{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic: Predicting who survived using Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using CSV\n",
    "using DataFrames\n",
    "using DataFramesMeta\n",
    "using DecisionTree\n",
    "using StatsBase\n",
    "using TypedTables\n",
    "using Plots\n",
    "plotly()\n",
    "IJulia.clear_output() ## to suppress all warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive Analysis\n",
    "Let's read in some data and have a look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symbol[:PassengerId, :Survived, :Pclass, :Name, :Sex, :Age, :SibSp, :Parch, :Ticket, :Fare, :Cabin, :Embarked]\n",
      "Symbol[:PassengerId, :Pclass, :Name, :Sex, :Age, :SibSp, :Parch, :Ticket, :Fare, :Cabin, :Embarked]"
     ]
    }
   ],
   "source": [
    "train = CSV.read(\"train.csv\", rows_for_type_detect=200);\n",
    "test = CSV.read(\"test.csv\", rows_for_type_detect=200);\n",
    "\n",
    "print(names(train), \"\\n\")\n",
    "print(names(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of survival:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of passengers survived: 342\n",
      "Number of passengers died: 549"
     ]
    }
   ],
   "source": [
    "print(\"Number of passengers survived: \", countmap(train[:Survived])[1], \"\\n\",\n",
    "      \"Number of passengers died: \", countmap(train[:Survived])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of Passenger classes booked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 1: 216\n",
      "Class 2: 184\n",
      "Class 3: 491"
     ]
    }
   ],
   "source": [
    "print(\"Class 1: \", countmap(train[:Pclass])[1], \"\\n\",\n",
    "      \"Class 2: \", countmap(train[:Pclass])[2], \"\\n\",\n",
    "      \"Class 3: \", countmap(train[:Pclass])[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of gender:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of male passengers: 577\n",
      "Number of female passengers: 314"
     ]
    }
   ],
   "source": [
    "print(\"Number of male passengers: \", countmap(train[:Sex])[\"male\"], \"\\n\",\n",
    "      \"Number of female passengers: \", countmap(train[:Sex])[\"female\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of age:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Stats:\n",
      "Mean:           29.699118\n",
      "Minimum:        0.420000\n",
      "1st Quartile:   20.125000\n",
      "Median:         28.000000\n",
      "3rd Quartile:   38.000000\n",
      "Maximum:        80.000000\n",
      "Length:         891\n",
      "Type:           Union{Float64, Nulls.Null}\n",
      "Number Missing: 177\n",
      "% Missing:      19.865320\n"
     ]
    }
   ],
   "source": [
    "describe(train[:Age])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of relatives on board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of siblings/spouses on board: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dict{Int64,Int64} with 7 entries:\n",
       "  0 => 608\n",
       "  4 => 18\n",
       "  2 => 28\n",
       "  3 => 16\n",
       "  5 => 5\n",
       "  8 => 7\n",
       "  1 => 209"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of siblings/spouses on board: \")\n",
    "countmap(train[:SibSp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parents/children aboard"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dict{Int64,Int64} with 7 entries:\n",
       "  0 => 678\n",
       "  4 => 4\n",
       "  2 => 80\n",
       "  3 => 5\n",
       "  5 => 5\n",
       "  6 => 1\n",
       "  1 => 118"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of parents/children aboard\")\n",
    "countmap(train[:Parch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Stats:\n",
      "Mean:           32.204208\n",
      "Minimum:        0.000000\n",
      "1st Quartile:   7.910400\n",
      "Median:         14.454200\n",
      "3rd Quartile:   31.000000\n",
      "Maximum:        512.329200\n",
      "Length:         891\n",
      "Type:           Float64\n"
     ]
    }
   ],
   "source": [
    "describe(train[:Fare])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Stats:\n",
      "Length:         891\n",
      "Type:           WeakRefString{UInt8}\n",
      "Number Unique:  891\n"
     ]
    }
   ],
   "source": [
    "describe(train[:Name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data transformations\n",
    "## Filter null values\n",
    "Null.null values are taken out here because the build_forest procedure called later does not know how to handle them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = @where(train, !(:Age.===null));\n",
    "train = @where(train, !(:Sex.===null));\n",
    "train = @where(train, !(:Pclass.===null));\n",
    "train = @where(train, !(:SibSp.===null));\n",
    "train = @where(train, !(:Parch.===null));\n",
    "train = @where(train, !(:Fare.===null));\n",
    "train = @where(train, !(:Embarked.===null));\n",
    "train = @where(train, !(:Name.===null));\n",
    "\n",
    "train[:Cabin] = collect(Nulls.replace(train[:Cabin], \"\"));\n",
    "test[:Cabin] = collect(Nulls.replace(test[:Cabin], \"\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert categorical features to ordered categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered!(train[:Sex], true);\n",
    "ordered!(test[:Sex], true);\n",
    "\n",
    "train = @orderby(train, :Age);\n",
    "train[:Age] = string.(train[:Age]);\n",
    "train[:Age] = CategoricalArray(train[:Age]);\n",
    "ordered!(train[:Age], true);\n",
    "\n",
    "test = @orderby(test, :Age);\n",
    "test[:Age] = string.(test[:Age]);\n",
    "test[:Age] = CategoricalArray(test[:Age]);\n",
    "ordered!(test[:Age], true);\n",
    "\n",
    "train = @orderby(train, :Pclass);\n",
    "train[:Pclass] = string.(train[:Pclass]);\n",
    "train[:Pclass] = CategoricalArray(train[:Pclass]);\n",
    "ordered!(train[:Pclass], true);\n",
    "\n",
    "test = @orderby(test, :Pclass);\n",
    "test[:Pclass] = string.(test[:Pclass]);\n",
    "test[:Pclass] = CategoricalArray(test[:Pclass]);\n",
    "ordered!(test[:Pclass], true);\n",
    "\n",
    "train = @orderby(train, :SibSp);\n",
    "train[:SibSp] = string.(train[:SibSp]);\n",
    "train[:SibSp] = CategoricalArray(train[:SibSp]);\n",
    "ordered!(train[:SibSp], true);\n",
    "\n",
    "test = @orderby(test, :SibSp);\n",
    "test[:SibSp] = string.(test[:SibSp]);\n",
    "test[:SibSp] = CategoricalArray(test[:SibSp]);\n",
    "ordered!(test[:SibSp], true);\n",
    "\n",
    "train = @orderby(train, :Parch);\n",
    "train[:Parch] = string.(train[:Parch]);\n",
    "train[:Parch] = CategoricalArray(train[:Parch]);\n",
    "ordered!(train[:Parch], true);\n",
    "\n",
    "test = @orderby(test, :Parch);\n",
    "test[:Parch] = string.(test[:Parch]);\n",
    "test[:Parch] = CategoricalArray(test[:Parch]);\n",
    "ordered!(test[:Parch], true);\n",
    "\n",
    "train = @orderby(train, :Fare);\n",
    "train[:Fare] = string.(train[:Fare]);\n",
    "train[:Fare] = CategoricalArray(train[:Fare]);\n",
    "ordered!(train[:Fare], true);\n",
    "\n",
    "test = @orderby(test, :Fare);\n",
    "test[:Fare] = string.(test[:Fare]);\n",
    "test[:Fare] = CategoricalArray(test[:Fare]);\n",
    "ordered!(test[:Fare], true);\n",
    "\n",
    "train = @orderby(train, :Cabin);\n",
    "train[:Cabin] = string.(train[:Cabin]);\n",
    "train[:Cabin] = CategoricalArray(train[:Cabin]);\n",
    "ordered!(train[:Cabin], true);\n",
    "\n",
    "test = @orderby(test, :Cabin);\n",
    "test[:Cabin] = string.(test[:Cabin]);\n",
    "test[:Cabin] = CategoricalArray(test[:Cabin]);\n",
    "ordered!(test[:Cabin], true);\n",
    "\n",
    "train = @orderby(train, :Embarked);\n",
    "train[:Embarked] = string.(train[:Embarked]);\n",
    "train[:Embarked] = CategoricalArray(train[:Embarked]);\n",
    "ordered!(train[:Embarked], true);\n",
    "\n",
    "test = @orderby(test, :Embarked);\n",
    "test[:Embarked] = string.(test[:Embarked]);\n",
    "test[:Embarked] = CategoricalArray(test[:Embarked]);\n",
    "ordered!(test[:Embarked], true);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature generation\n",
    "\n",
    "In the following we extract two features from the data that may have predictive value. Here it's merely an exercise and the predictive value remains untested. Usually I would want to know, though.\n",
    "\n",
    "Firstly, we extract the title from the name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String,Int64} with 5 entries:\n",
       "  \"Miss\"   => 145\n",
       "  \"Master\" => 36\n",
       "  \"\"       => 26\n",
       "  \"Mr\"     => 398\n",
       "  \"Mrs\"    => 107"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = @byrow! train begin\n",
    "    @newcol Title::Array{String}\n",
    "    :Title=\"\"\n",
    "    if(ismatch(r\"Mr\\.\", String(:Name)))\n",
    "        :Title=\"Mr\"\n",
    "    end\n",
    "    if(ismatch(r\"Mrs\\.\", String(:Name)))\n",
    "        :Title=\"Mrs\"\n",
    "    end\n",
    "    if(ismatch(r\"Miss\\.\", String(:Name)))\n",
    "        :Title=\"Miss\"\n",
    "    end\n",
    "    if(ismatch(r\"master|Master\", String(:Name)))\n",
    "        :Title=\"Master\"\n",
    "    end\n",
    "end;\n",
    "\n",
    "\n",
    "test = @byrow! test begin\n",
    "    @newcol Title::Array{String}\n",
    "    :Title=\"\"\n",
    "    if(ismatch(r\"Mr\\.\", String(:Name)))\n",
    "        :Title=\"Mr\"\n",
    "    end\n",
    "    if(ismatch(r\"Mrs\\.\", String(:Name)))\n",
    "        :Title=\"Mrs\"\n",
    "    end\n",
    "    if(ismatch(r\"Miss\\.\", String(:Name)))\n",
    "        :Title=\"Miss\"\n",
    "    end\n",
    "    if(ismatch(r\"master|Master\", String(:Name)))\n",
    "        :Title=\"Master\"\n",
    "    end\n",
    "end;\n",
    "\n",
    "countmap(train[:Title])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As another feature we extract the fact that some of the passengers had booked a private Cabin and may have been given precedence when deciding on whom to save first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String,Int64} with 2 entries:\n",
       "  \"Yes\" => 183\n",
       "  \"No\"  => 529"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = @byrow! train begin\n",
    "    @newcol Cabin_Booked::Array{String}\n",
    "    :Cabin_Booked=\"No\"\n",
    "    if(ismatch(r\"[a-zA-Z0-9]+\", String(:Cabin)))\n",
    "        :Cabin_Booked=\"Yes\"\n",
    "    end\n",
    "end;\n",
    "\n",
    "test = @byrow! test begin\n",
    "    @newcol Cabin_Booked::Array{String}\n",
    "    :Cabin_Booked=\"No\"\n",
    "    if(ismatch(r\"[a-zA-Z0-9]+\", String(:Cabin)))\n",
    "        :Cabin_Booked=\"Yes\"\n",
    "    end\n",
    "end;\n",
    "\n",
    "countmap(train[:Cabin_Booked])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting training and cross-validation sets\n",
    "\n",
    "Here wer create a training and a validation set with\n",
    " - n = 570 passengers (~80%) in training set and\n",
    " - n = 142 (~20%) in cross validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = size(train)[1];\n",
    "idx = sample(1:n, 570, replace=false, ordered=true);\n",
    "t = fill(true, n);\n",
    "t[idx] = false; ## true = cv, false = train\n",
    "\n",
    "cv_set = train[t, :];\n",
    "train_set = train[!t, :];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assert that procedure succeeded by checking that no passenger id from cv_set exists in train_set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "false"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any([cv_set[i, :PassengerId] in train_set[:PassengerId] for i in 1:size(cv_set)[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data sets for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list=[:Pclass, :Age, :Sex, :Parch, :SibSp, :Fare, :Embarked, :Title, :Cabin_Booked];\n",
    "\n",
    "labels = convert(Vector, train[:,:Survived]);\n",
    "features = convert(Matrix, train[:,feature_list]);\n",
    "\n",
    "labels_train = convert(Vector, train_set[:,:Survived]);\n",
    "features_train = convert(Matrix, train_set[:,feature_list]);\n",
    "\n",
    "labels_cv = convert(Vector, cv_set[:,:Survived]);\n",
    "features_cv = convert(Matrix, cv_set[:,feature_list]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning the hyperparameters\n",
    "\n",
    "The following steps test different values for the following hyperparameters used in the random forest training\n",
    "\n",
    "- number of features per sample\n",
    "- number of trees built\n",
    "- sample size as a percentage of the full sample\n",
    "- depth of the trees fitted\n",
    "\n",
    "in order to build the model.\n",
    "\n",
    "The values for the hyperparameters are saved in the following variables:\n",
    "\n",
    " - nf = number of features\n",
    " - nt = number of trees\n",
    " - p = portion of the sample\n",
    " - d = depth of the trees fitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxnf = 8\n",
    "maxnt = 50\n",
    "maxd = 40\n",
    "\n",
    "function tune_hyperparameters(maxnf, maxnt, maxd)\n",
    "    accuracy = Array{Float64, 4}(maxnf, maxnt, 10, maxd)\n",
    "    for nf in 1:maxnf, nt in 1:5:maxnt, p in 1:2:10, d in 1:2:maxd\n",
    "        model_train = build_forest(labels_train, features_train, nf, nt, p/10, d)\n",
    "        pred_cv = apply_forest(model_train, features_cv);\n",
    "        a=sum(labels_cv.== pred_cv)/length(labels_cv)\n",
    "        accuracy[nf, nt, p, d] =  a\n",
    "    end\n",
    "    return(accuracy)\n",
    "end\n",
    "\n",
    "accuracy = tune_hyperparameters(maxnf, maxnt, maxd);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our 4-dimensional array 'accuracy' gets filled with accuracy measurements from fitting a random forest classifier with the respective set of hyperparameters to the cross-validation data set. The step size is greater than 1 in order to save some time. \n",
    "\n",
    "The next step extracts the first to fifth best fits and the respective parameters which we take the median of in order to reduce the risk of overfitting by just using the best fit as a simple form of regularization.\n",
    "\n",
    "In order to get the 2nd, 3rd, ..., 5th best fit we delete the previous one. The collections idiom `1:end .!=idx` deselects the index at that place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters: [7, 31, 7, 15]\n",
      "performance: 0.8661971830985915\n",
      "parameters: [6, 45, 5, 26]\n",
      "performance: 0.8591549295774648\n",
      "parameters: [3, 26, 7, 20]\n",
      "performance: 0.852112676056338\n",
      "parameters: [2, 11, 1, 23]\n",
      "performance: 0.8450704225352113\n",
      "parameters: [2, 6, 2, 27]\n",
      "performance: 0.8450704225352113\n"
     ]
    }
   ],
   "source": [
    "idx1 = collect(ind2sub(size(accuracy), indmax(accuracy)))\n",
    "\n",
    "accuracy2nd = accuracy[1:end .!= idx1[1], 1:end .!=idx1[2], 1:end .!=idx1[3], 1:end .!=idx1[4]]\n",
    "idx2 = collect(ind2sub(size(accuracy2nd), indmax(accuracy2nd)))\n",
    "\n",
    "accuracy3rd = accuracy2nd[1:end .!= idx2[1], 1:end .!=idx2[2], 1:end .!=idx2[3], 1:end .!=idx2[4]]\n",
    "idx3 = collect(ind2sub(size(accuracy3rd), indmax(accuracy3rd)))\n",
    "\n",
    "accuracy4th = accuracy3rd[1:end .!= idx3[1], 1:end .!=idx3[2], 1:end .!=idx3[3], 1:end .!=idx3[4]]\n",
    "idx4 = collect(ind2sub(size(accuracy4th), indmax(accuracy4th)))\n",
    "\n",
    "accuracy5th = accuracy4th[1:end .!= idx4[1], 1:end .!=idx4[2], 1:end .!=idx4[3], 1:end .!=idx4[4]]\n",
    "idx5 = collect(ind2sub(size(accuracy5th), indmax(accuracy5th)))\n",
    "\n",
    "println(\"parameters: \", idx1)\n",
    "println(\"performance: \", accuracy[idx1[1], idx1[2], idx1[3], idx1[4]])\n",
    "println(\"parameters: \", idx2)\n",
    "println(\"performance: \", accuracy2nd[idx2[1], idx2[2], idx2[3], idx2[4]])\n",
    "println(\"parameters: \", idx3)\n",
    "println(\"performance: \", accuracy3rd[idx3[1], idx3[2], idx3[3], idx3[4]])\n",
    "println(\"parameters: \", idx4)\n",
    "println(\"performance: \", accuracy4th[idx4[1], idx4[2], idx4[3], idx4[4]])\n",
    "println(\"parameters: \", idx5)\n",
    "println(\"performance: \", accuracy5th[idx5[1], idx5[2], idx5[3], idx5[4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf = round(Int, median([idx1[1], idx2[1], idx3[1], idx4[1], idx5[1]]));\n",
    "nt = round(Int, median([idx1[2], idx2[2], idx3[2], idx4[2], idx5[2]]));\n",
    "p = round(median([idx1[3], idx2[3], idx3[3], idx4[3], idx5[3]]))/10;\n",
    "d = round(Int, median([idx1[4], idx2[4], idx3[4], idx4[4], idx5[4]]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 3\n",
      "Number of trees: 26\n",
      "Portion of the full sample: 0.5\n",
      "Tree depth: 23"
     ]
    }
   ],
   "source": [
    "print(\"Number of features: \", nf, \"\\n\",\n",
    "      \"Number of trees: \", nt, \"\\n\",\n",
    "      \"Portion of the full sample: \", p, \"\\n\",\n",
    "      \"Tree depth: \", d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-fold cross-validation is performed with n = 10 number of folds (=splits of the original dataset) with training on a a subsample determined by p of the 9 folds and predicting the 10th."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = nfoldCV_forest(labels, features, nf, nt, 10, p);\n",
    "IJulia.clear_output() ## to suppress all output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy achieved: 0.7985915492957747\n",
      "Standard deviation of the performance: 0.03639633322688132"
     ]
    }
   ],
   "source": [
    "print(\"Average accuracy achieved: \", mean(acc), \"\\n\",\n",
    "      \"Standard deviation of the performance: \", std(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script src=\"/home/alexander/.julia/v0.6/Plots/src/backends/../../deps/plotly-latest.min.js\"></script>    <div id=\"3bd4043b-9f3d-413b-ba3b-90e3e568b602\" style=\"width:600px;height:400px;\"></div>\n",
       "    <script>\n",
       "    PLOT = document.getElementById('3bd4043b-9f3d-413b-ba3b-90e3e568b602');\n",
       "    Plotly.plot(PLOT, [{\"showlegend\":true,\"marker\":{\"color\":\"rgba(0, 154, 250, 1.000)\"},\"xaxis\":\"x\",\"colorbar\":{\"title\":\"\"},\"y\":[1.0,5.0,3.0,1.0],\"type\":\"bar\",\"name\":\"y1\",\"yaxis\":\"y\",\"orientation\":\"v\",\"x\":[0.725,0.775,0.825,0.875]}], {\"showlegend\":false,\"xaxis\":{\"gridwidth\":0.5,\"tickvals\":[0.0,0.2,0.4,0.6000000000000001,0.8,1.0],\"visible\":true,\"ticks\":\"inside\",\"range\":[0.0,1.0],\"domain\":[0.02137649460484106,0.9934383202099737],\"tickmode\":\"array\",\"linecolor\":\"rgba(0, 0, 0, 1.000)\",\"showgrid\":true,\"title\":\"Accuracy\",\"mirror\":false,\"tickangle\":0,\"showline\":true,\"gridcolor\":\"rgba(0, 0, 0, 0.100)\",\"titlefont\":{\"color\":\"rgba(0, 0, 0, 1.000)\",\"family\":\"sans-serif\",\"size\":15},\"tickcolor\":\"rgb(0, 0, 0)\",\"ticktext\":[\"0.0\",\"0.2\",\"0.4\",\"0.6\",\"0.8\",\"1.0\"],\"zeroline\":false,\"type\":\"-\",\"tickfont\":{\"color\":\"rgba(0, 0, 0, 1.000)\",\"family\":\"sans-serif\",\"size\":11},\"zerolinecolor\":\"rgba(0, 0, 0, 1.000)\",\"anchor\":\"y\"},\"paper_bgcolor\":\"rgba(255, 255, 255, 1.000)\",\"annotations\":[],\"height\":400,\"margin\":{\"l\":0,\"b\":20,\"r\":0,\"t\":20},\"plot_bgcolor\":\"rgba(255, 255, 255, 1.000)\",\"yaxis\":{\"gridwidth\":0.5,\"tickvals\":[0.0,1.0,2.0,3.0,4.0,5.0],\"visible\":true,\"ticks\":\"inside\",\"tickmode\":\"array\",\"domain\":[0.07581474190726165,0.9901574803149606],\"linecolor\":\"rgba(0, 0, 0, 1.000)\",\"showgrid\":true,\"title\":\"\",\"mirror\":false,\"tickangle\":0,\"showline\":true,\"gridcolor\":\"rgba(0, 0, 0, 0.100)\",\"titlefont\":{\"color\":\"rgba(0, 0, 0, 1.000)\",\"family\":\"sans-serif\",\"size\":15},\"tickcolor\":\"rgb(0, 0, 0)\",\"ticktext\":[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\"],\"zeroline\":false,\"type\":\"-\",\"tickfont\":{\"color\":\"rgba(0, 0, 0, 1.000)\",\"family\":\"sans-serif\",\"size\":11},\"zerolinecolor\":\"rgba(0, 0, 0, 1.000)\",\"anchor\":\"x\"},\"width\":600});\n",
       "    </script>\n"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "histogram(acc,\n",
    "          xaxis = (\"Accuracy\", (0,1)),\n",
    "          legend = :none)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8028169014084507"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_train = build_forest(labels_train, features_train, nf, nt, p, d)\n",
    "pred_train = apply_forest(model_train, features_cv);\n",
    "sum(labels_cv .== pred_train)/length(labels_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction on test set using all training examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test = convert(Matrix, test[:,feature_list]);\n",
    "model = build_forest(labels, features, nf, nt, p, d)\n",
    "pred = apply_forest(model, features_test);\n",
    "\n",
    "test[:Survived] = pred;\n",
    "CSV.write(\"titanic_prediction.csv\", test[[:PassengerId, :Survived]]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This classifier scored accuracy = 0.794 on the corresponding Kaggle competition."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia nodeps 0.6.0",
   "language": "julia",
   "name": "julia-nodeps-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
